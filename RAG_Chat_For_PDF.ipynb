{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKKU09xVE0Kl"
      },
      "source": [
        "###  Checking For GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NLfN5_VBHaw",
        "outputId": "335ded78-6c05-422c-8bb1-a02acdfe095f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jan  2 18:26:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERFOtylzEb0t",
        "outputId": "59b3b28c-a777-4647-d66e-4f334485fa2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq torch==2.0.1 --progress-bar off\n",
        "!pip install -qqq transformers==4.31.0 --progress-bar off\n",
        "!pip install -qqq langchain==0.0.266 --progress-bar off\n",
        "!pip install -qqq chromadb==0.4.5 --progress-bar off\n",
        "!pip install -qqq pypdf==3.15.0 --progress-bar off\n",
        "!pip install -qqq xformers==0.0.20 --progress-bar off\n",
        "!pip install -qqq sentence_transformers==2.2.2 --progress-bar off\n",
        "!pip install -qqq InstructorEmbedding==1.0.1 --progress-bar off\n",
        "!pip install -qqq pdf2image==1.16.3 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQwwBXYJE8hT",
        "outputId": "f17fe351-63ef-4524-ee5a-25ba712b5290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torchtext==0.16.0 in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.1.0+cu121 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.16.0) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0) (9.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.7.0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.0 torchdata==0.7.0 torchtext==0.16.0 torchvision==0.16.0 torchaudio==2.1.0+cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I45JPU74IMN1",
        "outputId": "dd4337bb-5459-454c-8a17-dfe6692eb739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qqq auto_gptq-0.4.1+cu118-cp310-cp310-linux_x86_64.whl --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDKntn9FIa8f",
        "outputId": "143bb020-9c54-4d25-bd42-6536d71711e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5JzTqtcInLk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain import HuggingFacePipeline, PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from pdf2image import convert_from_path\n",
        "from transformers import AutoTokenizer, TextStreamer, pipeline\n",
        "\n",
        "DEVICE = \"cuda:0\" if tf.config.list_physical_devices(\"GPU\") else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lw11XQ3Ji0W"
      },
      "source": [
        "###  Creating a directory to save the pdf's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2obqRJeJIy4e"
      },
      "outputs": [],
      "source": [
        "!mkdir pdfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY2mv_NcKr3o"
      },
      "source": [
        "###  Getting the pdf's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9QDqFm7JKJF"
      },
      "outputs": [],
      "source": [
        "!gdown 1v-Rn1FVU1pLTAQEgm0N9oB6cExMoebZr -O pdfs/tesla-earnings-report.pdf\n",
        "!gdown 1Xc890jrQvCExAkryVWAttsv1DBLdVefN -O pdfs/nvidia-earnings-report.pdf\n",
        "!gdown 1Epz-SQ3idPpoz75GlTzzomag8gplzLv8 -O pdfs/meta-earnings-report.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QftxT0VkJy0Y"
      },
      "outputs": [],
      "source": [
        "meta_images = convert_from_path(\"pdfs/meta-earnings-report.pdf\", dpi=88)\n",
        "meta_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_hORC_-KZzr"
      },
      "outputs": [],
      "source": [
        "nvidia_images = convert_from_path(\"pdfs/nvidia-earnings-report.pdf\", dpi=88)\n",
        "nvidia_images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjmwTSTUKqFV"
      },
      "outputs": [],
      "source": [
        "tesla_images = convert_from_path(\"pdfs/tesla-earnings-report.pdf\", dpi=88)\n",
        "tesla_images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seckDayYK8NK"
      },
      "source": [
        "###  Creating the Vector Database to store the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LzuUixpK0o7"
      },
      "outputs": [],
      "source": [
        "!rm -rf \"db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5ZWHDzK8LCwT",
        "outputId": "84da4529-1cd5-4ef3-d4fe-528851e162c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "docs = loader.load()\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AurL5mQiLF0U",
        "outputId": "a5d91197-60b2-4153-fea5-02a919437c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "32hsAOrzLMka",
        "outputId": "0efaa0f3-56bb-44fd-fd10-510a65277505"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "355"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYwtksblNV1z"
      },
      "source": [
        "###  Here we are using ChromaDB vector database to store the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a3cU4JI9NRL9",
        "outputId": "14a1c27a-ee0d-4129-b85b-59aaf7172923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 20.1 s, sys: 333 ms, total: 20.5 s\n",
            "Wall time: 23.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lswvo4eNhhK"
      },
      "source": [
        "###  Using LLAMA2 13B GPT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKGJxpzyNgFS"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
        "model_basename = \"model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "\n",
        "model = AutoGPTQForCausalLM.from_quantized(\n",
        "    model_name_or_path,\n",
        "    revision=\"gptq-4bit-128g-actorder_True\",\n",
        "    model_basename=model_basename,\n",
        "    use_safetensors=True,\n",
        "    trust_remote_code=True,\n",
        "    inject_fused_attention=False,\n",
        "    device=DEVICE,\n",
        "    quantize_config=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq6gVCUqNdau"
      },
      "outputs": [],
      "source": [
        "##Checking the device GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKhZWKQCPTGj"
      },
      "outputs": [],
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
        "    return f\"\"\"\n",
        "[INST] <>\n",
        "{system_prompt}\n",
        "<>\n",
        "\n",
        "{prompt} [/INST]\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVksMzxBPZR0"
      },
      "outputs": [],
      "source": [
        "\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxqyfaYBPe4A"
      },
      "outputs": [],
      "source": [
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.15,\n",
        "    streamer=streamer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3435MU1PhuD"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-pfe8YkQdf7"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "\n",
        "template = generate_prompt(\n",
        "    \"\"\"\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\",\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "off4LnlRQ2mI"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW5d95B8Q8UZ"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLkwjxr-RwUI"
      },
      "source": [
        "###  Testing the PDF's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzLRHmPpRBcZ"
      },
      "outputs": [],
      "source": [
        "result = qa_chain(\"What is the per share revenue for Meta during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T71DsB3R391"
      },
      "outputs": [],
      "source": [
        "len(result[\"source_documents\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyHWs8R3SJn-"
      },
      "outputs": [],
      "source": [
        "print(result[\"source_documents\"][0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LburCrf5SRlQ",
        "outputId": "2e40a311-69fd-45f4-f491-4bf29c4c514f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I can't determine the per share revenue for Tesla in 2023 based on the information provided. The financial statements only provide total revenues and do not break down the figures by shares outstanding. Therefore, I cannot calculate the per share revenue.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the per share revenue for Tesla during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E1PEEUFfSXbH",
        "outputId": "692840f1-86b1-445b-846a-6a7a82182a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Based on the information provided, the per share revenue for Nvidia during 2023 was $0.83. This is calculated by dividing the total revenue for the period ($7,192 million) by the weighted average number of shares outstanding (basic and diluted) during the period (2,470 million).\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the per share revenue for Nvidia during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VU1-ZjFzTrAt",
        "outputId": "a0040875-90e5-4f56-d627-cd08220a2c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PART I. FINANCIAL INFORMATION\n",
            "ITEM 1.  FINANCIAL STATEMENTS (UNAUDITED)\n",
            "NVIDIA CORPORATION AND SUBSIDIARIES\n",
            "CONDENSED CONSOLIDATED STATEMENTS OF INCOME\n",
            "(In millions, except per share data)\n",
            "(Unaudited)\n",
            " Three Months Ended\n",
            " April 30, May 1,\n",
            "2023 2022\n",
            "Revenue $ 7,192 $ 8,288 \n",
            "Cost of revenue 2,544 2,857 \n",
            "Gross profit 4,648 5,431 \n",
            "Operating expenses   \n",
            "Research and development 1,875 1,618 \n",
            "Sales, general and administrative 633 592 \n",
            "Acquisition termination cost â€” 1,353 \n",
            "Total operating expenses 2,508 3,563 \n",
            "Income from operations 2,140 1,868 \n",
            "Interest income 150 18 \n",
            "Interest expense (66) (68)\n",
            "Other, net (15) (13)\n",
            "Other income (expense), net 69 (63)\n",
            "Income before income tax 2,209 1,805 \n",
            "Income tax expense 166 187 \n",
            "Net income $ 2,043 $ 1,618 \n",
            "Net income per share:\n",
            "Basic $ 0.83 $ 0.65 \n",
            "Diluted $ 0.82 $ 0.64 \n",
            "Weighted average shares used in per share computation:\n",
            "Basic 2,470 2,506 \n",
            "Diluted 2,490 2,537 \n",
            "See accompanying Notes to Condensed Consolidated Financial Statements.\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(result[\"source_documents\"][1].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i2Cya2GebMA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f46855-7966-444a-c5bb-ca4f30e02f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the information provided in the press release, Meta's estimated YOY revenue for 2023 is expected to be between $32-34.5 billion, which represents an increase of 11-16% over 2022.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Meta during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "bbKfmDH4b9xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aea14fe-0a9b-4d3f-eaf1-fdd2f9a93331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I can provide information on the estimated year-over-year (YOY) revenue for Tesla based on the provided financial statements.\n",
            "\n",
            "To calculate the estimated YOY revenue for Tesla during 2023, we need to compare the revenues for the six months ended June 30, 2023, with those for the same period in 2022.\n",
            "\n",
            "According to the financial statements, the total revenues for the six months ended June 30, 2023, were $24,927 million, while the total revenues for the same period in 2022 were $16,934 million. This represents a year-over-year increase of $7,993 million or approximately 47%.\n",
            "\n",
            "Therefore, based on this analysis, the estimated YOY revenue for Tesla during 2023 is approximately 47% higher than in 2022.\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Tesla during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3C4pe7icAxs"
      },
      "outputs": [],
      "source": [
        "result = qa_chain(\"What is the estimated YOY revenue for Nvidia during 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gR2RTbScSEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab39bd7-be98-4369-f879-f3258409e15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I cannot determine which company is more profitable during 2023 between Meta, Nvidia, and Tesla based on the information provided. The passage only discusses Nvidia's financial condition and results of operations but does not provide any information about Meta or Tesla's financial performance during 2023. Additionally, it is important to note that profitability can be influenced by various factors such as "
          ]
        }
      ],
      "source": [
        "result = qa_chain(\n",
        "    \"Which company is more profitable during 2023 Meta, Nvidia or Tesla and why?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6nOxo0dcVJO"
      },
      "outputs": [],
      "source": [
        "result = qa_chain(\n",
        "    \"Choose one company to invest (Tesla, Nvidia or Meta) to maximize your profits for the long term (10+ years)?\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}